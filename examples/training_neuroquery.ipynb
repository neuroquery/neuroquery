{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Advanced example: training a NeuroQuery model from scratch\n\nIn this example, we train a NeuroQuery model from TFIDF descriptors and peak\nactivation coordinates for around 13K neuroimaging studies.\n\nWe transform the coordinates into brain maps, fit a regression model, show an\nexample prediction, and store the trained model.\n\nThis example is more computation-intensive than the others. It runs in around\n40 minutes in total (around 25 mn to transform coordinates into brain maps, and\n15 mn to fit the regression model) and uses up to 6 GB of memory.\n\nNote: for this demo we use a very coarse resolution of brain maps (6mm voxels),\nchange `target_affine` to e.g. `(4, 4, 4)` to increase resolution. With 4mm\nresolution, the example requires around 60 mn and 14 GB of memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collect training data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pathlib\n\nfrom scipy import sparse\nimport pandas as pd\nfrom joblib import Memory\nfrom nilearn import plotting\n\nfrom neuroquery import datasets\nfrom neuroquery.img_utils import coordinates_to_maps\nfrom neuroquery.smoothed_regression import SmoothedRegression\nfrom neuroquery.tokenization import TextVectorizer\nfrom neuroquery.encoding import NeuroQueryModel\n\n# Choose where to store the cache and the model once it is trained\noutput_directory = \"trained_text_to_brain_model\"\ncache_directory = \"cache\"\n\ndata_dir = pathlib.Path(datasets.fetch_neuroquery_model())\n\ncorpus_metadata = pd.read_csv(str(data_dir / \"corpus_metadata.csv\"))\nvectorizer = TextVectorizer.from_vocabulary_file(\n    str(data_dir / \"vocabulary.csv\")\n)\n\n# The TFIDF features stored with NeuroQuery data correspond to the terms in\n# `vocabulary.csv` and the studies in `corpus_metadata.csv`;\n# see `README.md` in the data directory for details\ntfidf = sparse.load_npz(str(data_dir / \"corpus_tfidf.npz\"))\n\ncoordinates = pd.read_csv(datasets.fetch_peak_coordinates())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform the coordinates into brain maps\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We cache the `coordinates_to_maps` function with joblib to avoid recomputing\n# this if we train a new model.\ncoord_to_maps = Memory(cache_directory).cache(coordinates_to_maps)\n\n# You can set target_affine to a different value to increase image resolution\n# or reduce computation time. The model on neuroquery.org uses 4 mm\n# resolution i.e. target_affine=(4, 4, 4)\n# You can also adjust the smoothing by setting `fwhm` (Full Width at Half\n# maximum)\nbrain_maps, masker = coord_to_maps(\n    coordinates, target_affine=(6, 6, 6), fwhm=9.0\n)\nbrain_maps = brain_maps[(brain_maps.values != 0).any(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure TFIDF and brain maps are aligned (correspond to the same studies)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pmids = brain_maps.index.intersection(corpus_metadata[\"pmid\"])\nkept_idx = corpus_metadata[\"pmid\"].isin(pmids)\ntfidf = tfidf.A[kept_idx, :]\nbrain_maps = brain_maps.loc[pmids, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the regression model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regressor = SmoothedRegression(alphas=[1.0, 10.0, 100.0])\n\nprint(\n    \"Fitting smoothed regression model on {} samples...\".format(tfidf.shape[0])\n)\nregressor.fit(tfidf, brain_maps.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build a NeuroQuery model and serialize it\nIt is an interface to the regression model that tokenizes the text of\nqueries, unmasks the predicted brain maps, and formats the outputs.\nThis is the type of object that we will serialize and that is used in other\nexamples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corpus_metadata = corpus_metadata.set_index(\"pmid\").loc[pmids, :].reset_index()\nencoder = NeuroQueryModel(\n    vectorizer,\n    regressor,\n    masker.mask_img_,\n    corpus_info={\n        \"tfidf\": sparse.csr_matrix(tfidf),\n        \"metadata\": corpus_metadata,\n    },\n)\nencoder.to_data_dir(output_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show an example prediction from our freshly trained model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "query = \"Reading words\"\nprint('Encoding \"{}\"'.format(query))\n\nresult = encoder(query)\n\nplotting.view_img(result[\"brain_map\"], threshold=3.0).open_in_browser()\n\nprint(\"Similar words:\")\nprint(result[\"similar_words\"].head())\nprint(\"\\nSimilar documents:\")\nprint(result[\"similar_documents\"].head())\n\nprint(\"\\nmodel saved in {}\".format(output_directory))\n\n# Display in notebook\nplotting.view_img(result[\"brain_map\"], threshold=3.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the model is trained and saved, it can easily be loaded in a later\nsession\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "encoder = NeuroQueryModel.from_data_dir(output_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\nWe have trained and used a NeuroQuery model based on coordinates and TFIDF\nfeatures. As we have seen, in order to train a model, we need:\n- An array of TFIDF features\n- An array of masked brain maps (shape n samples x n voxels), which can be\n  easily obtained from coordinates with `coordinates_to_maps`, such that each\n  brain map corresponds to a row of the TFIDF matrix\n\nThen to construct a `NeuroQueryModel` that can answer queries, we also need\nto build a `TextVectorizer`, either by reading a vocabulary file as is done\nin this example, or simply by calling\n`TextVectorizer.from_vocabulary(feature_names)`, where `feature_names` is a\nlist of strings giving the terms that correspond to each column of the TFIDF\nmatrix.\nFinally, optionally, `NeuroQueryModel` can also be provided with data about\nthe corpus (e.g. article titles), which will be used to describe documents\nrelated to queries if available.\n\nTherefore a model can be trained and used using a TFIDF matrix, a DataFrame\nof coordinates or an array of brain maps, and a vocabulary list only. It does\nnot require a dataset on disk with any particular directory structure.\n\nFinally, the TFIDF features themselves can easily be obtained with\n`TextVectorizer`, or similar vectorizers from `scikit-learn`, if you have a\ncorpus of text. Here we use the TFIDF distributed in `neuroquery_data`\nbecause we do not have access to the corpus of text they were derived from.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}